{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TUBAYc7B0Ju"
      },
      "outputs": [],
      "source": [
        "from math import inf\n",
        "#psuedo code of the node\n",
        "''' class Node:\n",
        "Attributes\n",
        " . feature: the feature index used for splitting\n",
        " . threshold: the value to split the feature on.\n",
        "\n",
        "'''\n",
        "\n",
        "class Node:\n",
        "  def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.value = value\n",
        "\n",
        "  def is_leaf_node(self):\n",
        "    return self.value is not None\n",
        "class DecisionTreeRegressor:\n",
        "  def __init__(self):\n",
        "    self.root=None\n",
        "  def fit(self,X,y):\n",
        "   self.root=self._build_tree(X,y)\n",
        "  def _build_tree(self,X,y, depth=0):\n",
        "    n_samples, n_features = X.shape\n",
        "    n_labels = len(np.unique(y))\n",
        "    if(n_labels==1):\n",
        "      leaf_value=self._mean_of_labels(y)\n",
        "      return Node(value=leaf_value)\n",
        "    feat_idx=np.arange(n_features)\n",
        "    best_feature, best_threshold = self._best_split(X, y,feat_idx)\n",
        "    left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
        "    left=self._build_tree(X[left_idxs,:],y[left_idxs])\n",
        "    right=self._build_tree(X[right_idxs,:],y[right_idxs])\n",
        "    return Node(best_feature,best_threshold,left,right)\n",
        "  def _most_common_label(self,y):\n",
        "    unique_labels,counts=np.unique(y,return_counts=True)\n",
        "    return unique_labels[np.argmax(counts)] # argmax return index of the max value\n",
        "  def _mean_of_labels(self,y):\n",
        "    return np.mean(y)\n",
        "  def _split(self,X_column,split_thresh):\n",
        "    left_idxs=np.argwhere(X_column<=split_thresh).flatten()\n",
        "    right_idxs=np.argwhere(X_column>split_thresh).flatten()\n",
        "    return left_idxs,right_idxs\n",
        "  def _best_split(self,X,y,feat_idxs):\n",
        "    best_gain,split_idx,split_thresh=float('inf'),None,None\n",
        "    for feat_idx in feat_idxs:\n",
        "      X_column=X[:,feat_idx]\n",
        "      X_column_sorted=np.sort(X_column)\n",
        "      thresholds=(X_column_sorted[:-1]+X_column_sorted[1:])/2\n",
        "      for threshold in thresholds:\n",
        "        gain=self._information_gain(y,X_column,threshold)\n",
        "        if(gain<best_gain):\n",
        "          best_gain=gain\n",
        "          split_idx=feat_idx\n",
        "          split_thresh=threshold\n",
        "      return split_idx,split_thresh\n",
        "  def _information_gain(self,y,X_column,threshold):\n",
        "    left_idxs, right_idxs=self._split(X_column,threshold)\n",
        "    if(len(left_idxs)==0 or len(right_idxs)==0):\n",
        "      return 0\n",
        "    n,n_l,n_r = len(y),len(left_idxs),len(right_idxs)\n",
        "    e_l,e_r=self._entropy(y[left_idxs]),self._entropy(y[right_idxs])\n",
        "    child_entropy=(n_l/n)*e_l+(n_r/n)*e_r\n",
        "    information_gain= child_entropy\n",
        "    return information_gain\n",
        "  def _entropy(self,y):#calculating mean square error or deviation\n",
        "    y1=y-np.mean(y)\n",
        "    return np.mean((y1-y)**2)\n",
        "  def predict(self,X):\n",
        "    pred= np.array([self._traverse_tree(x,self.root) for x in X])\n",
        "    return pred\n",
        "  def _traverse_tree(self,x,node):\n",
        "    if node.is_leaf_node():\n",
        "      return node.value\n",
        "    if x[node.feature]<=node.threshold:\n",
        "      return self._traverse_tree(x,node.left)\n",
        "    return self._traverse_tree(x,node.right)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X=np.array([[1,2],[2,3],[3,4],[4,5],[5,6]])\n",
        "y=np.array([1,1,0,0,0])\n",
        "regressor=DecisionTreeRegressor()\n",
        "regressor.fit(X,y)\n",
        "y_pred=regressor.predict(X)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zCnCbZYGvWt",
        "outputId": "5bb28970-bc0e-4b99-d312-afb240017b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model\n",
        "mse=np.mean((y-y_pred)**2)\n",
        "print(f\"mean square error : {mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usFceqFYHKFl",
        "outputId": "ac2086aa-0cc8-40bc-ade1-081fbc732c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean square error : 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def r2_score_percentage(y_true,y_pred):\n",
        "  #calcualte the total sum of squares(TSS)\n",
        "  tss=np.sum((y_true-np.mean(y_true))**2)\n",
        "  #calcualte the residual sum of squares(rss)\n",
        "  rss=np.sum((y_true-y_pred)**2)\n",
        "  r2_score=1-(rss/tss)\n",
        "  r2_precentage=r2_score*100\n",
        "  return r2_precentage"
      ],
      "metadata": {
        "id": "Afw3t0sNHqUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score=r2_score_percentage(y,y_pred)"
      ],
      "metadata": {
        "id": "_ic7b5UzH0u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGqSbrLEJii_",
        "outputId": "82ebc07f-7d23-410e-ed97-229e3f1804a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import inf\n",
        "#psuedo code of the node\n",
        "''' class Node:\n",
        "Attributes\n",
        " . feature: the feature index used for splitting\n",
        " . threshold: the value to split the feature on.\n",
        "\n",
        "'''\n",
        "\n",
        "class Node:\n",
        "  def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.value = value\n",
        "\n",
        "  def is_leaf_node(self):\n",
        "    return self.value is not None\n",
        "class DecisionTreeRegressor:\n",
        "  def __init__(self,max_depth):\n",
        "    self.root=None\n",
        "    self.max_depth=max_depth\n",
        "  def fit(self,X,y):\n",
        "   self.root=self._build_tree(X,y)\n",
        "  def _build_tree(self,X,y, depth=0):\n",
        "    n_samples, n_features = X.shape\n",
        "    n_labels = len(np.unique(y))\n",
        "    if(n_labels==1 or self.max_depth is not None and depth>=self.max_depth):\n",
        "      leaf_value=self._mean_of_labels(y)\n",
        "      return Node(value=leaf_value)\n",
        "    feat_idx=np.arange(n_features)\n",
        "    best_feature, best_threshold = self._best_split(X, y,feat_idx)\n",
        "    left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
        "    left=self._build_tree(X[left_idxs,:],y[left_idxs],depth+1)\n",
        "    right=self._build_tree(X[right_idxs,:],y[right_idxs],depth+1)\n",
        "    return Node(best_feature,best_threshold,left,right)\n",
        "  def _most_common_label(self,y):\n",
        "    unique_labels,counts=np.unique(y,return_counts=True)\n",
        "    return unique_labels[np.argmax(counts)] # argmax return index of the max value\n",
        "  def _mean_of_labels(self,y):\n",
        "    return np.mean(y)\n",
        "  def _split(self,X_column,split_thresh):\n",
        "    left_idxs=np.argwhere(X_column<=split_thresh).flatten()\n",
        "    right_idxs=np.argwhere(X_column>split_thresh).flatten()\n",
        "    return left_idxs,right_idxs\n",
        "  def _best_split(self,X,y,feat_idxs):\n",
        "    best_gain,split_idx,split_thresh=float('inf'),None,None\n",
        "    for feat_idx in feat_idxs:\n",
        "      X_column=X[:,feat_idx]\n",
        "      X_column_sorted=np.sort(X_column)\n",
        "      thresholds=(X_column_sorted[:-1]+X_column_sorted[1:])/2\n",
        "      for threshold in thresholds:\n",
        "        gain=self._information_gain(y,X_column,threshold)\n",
        "        if(gain<best_gain):\n",
        "          best_gain=gain\n",
        "          split_idx=feat_idx\n",
        "          split_thresh=threshold\n",
        "      return split_idx,split_thresh\n",
        "  def _information_gain(self,y,X_column,threshold):\n",
        "    left_idxs, right_idxs=self._split(X_column,threshold)\n",
        "    if(len(left_idxs)==0 or len(right_idxs)==0):\n",
        "      return 0\n",
        "    n,n_l,n_r = len(y),len(left_idxs),len(right_idxs)\n",
        "    e_l,e_r=self._entropy(y[left_idxs]),self._entropy(y[right_idxs])\n",
        "    child_entropy=(n_l/n)*e_l+(n_r/n)*e_r\n",
        "    information_gain= child_entropy\n",
        "    return information_gain\n",
        "  def _entropy(self,y):#calculating mean square error or deviation\n",
        "    y1=y-np.mean(y)\n",
        "    return np.mean((y1-y)**2)\n",
        "  def predict(self,X):\n",
        "    pred= np.array([self._traverse_tree(x,self.root) for x in X])\n",
        "    return pred\n",
        "  def _traverse_tree(self,x,node):\n",
        "    if node.is_leaf_node():\n",
        "      return node.value\n",
        "    if x[node.feature]<=node.threshold:\n",
        "      return self._traverse_tree(x,node.left)\n",
        "    return self._traverse_tree(x,node.right)\n",
        "\n"
      ],
      "metadata": {
        "id": "0wTNlhg7JkA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor=DecisionTreeRegressor(max_depth=3)"
      ],
      "metadata": {
        "id": "Choi1mGEMcSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.fit(X,y)"
      ],
      "metadata": {
        "id": "clpb54rQMnpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=regressor.predict(X)"
      ],
      "metadata": {
        "id": "usSy3wgLMr77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGnVQOODMwpy",
        "outputId": "6202a0f4-86ca-4b88-d445-2fcaf79c0562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1. , 0.5, 0.5, 0. , 0. ])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "besgsQOkM3KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using sklearn gradient boosting"
      ],
      "metadata": {
        "id": "8Q3cBX7UM8pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "X=np.array([[1,2],[2,3],[3,4],[4,5],[5,6]])\n",
        "y=np.array([1,1,0,0,0])\n",
        "regressor=GradientBoostingRegressor(n_estimators=100,learning_rate=0.1,max_depth=2,random_state=42)\n",
        "regressor.fit(X,y)\n",
        "y_pred=regressor.predict(X)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHbkJWRWND5V",
        "outputId": "444c586a-b337-4d02-c55f-e5d3964d7047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.99984063e-01, 9.99984063e-01, 1.06245596e-05, 1.06245596e-05,\n",
              "       1.06245596e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse=np.mean((y-y_pred)**2)\n",
        "print(f\"mean square error : {mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVHhRSmKNq8w",
        "outputId": "691e87e6-f1bd-4463-a739-b033acf64186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean square error : 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score=r2_score_percentage(y,y_pred)"
      ],
      "metadata": {
        "id": "NoZOfiw1NrkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7WWdITdNwUc",
        "outputId": "30b01d36-27d1-4c56-b0e6-705c1bc94189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.99999992944922"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4OXMSzqANxyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#without inbuilt functions"
      ],
      "metadata": {
        "id": "y_Umd2N4OGeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import inf\n",
        "class Node:\n",
        "  def __init__(self, n_estimators=100,learning_rate=0.01,max_depth=1):\n",
        "    self.n_estimators=n_estimators\n",
        "    self.learning_rate=learning_rate\n",
        "    self.max_depth=max_depth\n",
        "    self.trees=[]\n",
        "\n",
        "  def is_leaf_node(self):\n",
        "    return self.value is not None\n",
        "class DecisionTree:\n",
        "  def __init__(self):\n",
        "    self.root=None\n",
        "  def fit(self,X,y):\n",
        "    m=len(y)\n",
        "    self.intial_prediction=np.mean(y)\n",
        "    residuals=y-self.intial_prediction\n",
        "    for _ in range(self.n_estimators):\n",
        "      tree=DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "      tree.fit(X,residuals)\n",
        "      predictions=tree.predict(X)\n",
        "      residuals-=self.learning_rate*predictions\n",
        "      self.trees.append(tree)\n",
        "  def _most_common_label(self,y):\n",
        "    unique_labels,counts=np.unique(y,return_counts=True)\n",
        "    return unique_labels[np.argmax(counts)]\n",
        "  def _build_tree(self,X,y, depth=0):\n",
        "    n_samples, n_features = X.shape\n",
        "    n_labels = len(np.unique(y))\n",
        "    if(n_labels==1):\n",
        "      leaf_value=self._most_common_label(y)\n",
        "      return Node(value=leaf_value)\n",
        "    feat_idx=np.arange(n_features)\n",
        "    best_feature, best_threshold = self._best_split(X, y,feat_idx)\n",
        "    left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
        "    left=self._build_tree(X[left_idxs,:],y[left_idxs])\n",
        "    right=self._build_tree(X[right_idxs,:],y[right_idxs])\n",
        "    return Node(best_feature,best_threshold,left,right)\n",
        "   # argmax return index of the max value\n",
        "  def _split(self,X_column,split_thresh):\n",
        "    left_idxs=np.argwhere(X_column<=split_thresh).flatten()\n",
        "    right_idxs=np.argwhere(X_column>split_thresh).flatten()\n",
        "    return left_idxs,right_idxs\n",
        "  def _best_split(self,X,y,feat_idxs):\n",
        "    best_gain,split_idx,split_thresh=float('inf'),None,None\n",
        "    for feat_idx in feat_idxs:\n",
        "      X_column=X[:,feat_idx]\n",
        "      X_column_sorted=np.sort(X_column)\n",
        "      thresholds=(X_column_sorted[:-1]+X_column_sorted[1:])/2\n",
        "      for threshold in thresholds:\n",
        "        gain=self._information_gain(y,X_column,threshold)\n",
        "        if(gain<best_gain):\n",
        "          best_gain=gain\n",
        "          split_idx=feat_idx\n",
        "          split_thresh=threshold\n",
        "      return split_idx,split_thresh\n",
        "  def _information_gain(self,y,X_column,threshold):\n",
        "    left_idxs, right_idxs=self._split(X_column,threshold)\n",
        "    if(len(left_idxs)==0 or len(right_idxs)==0):\n",
        "      return 0\n",
        "    n,n_l,n_r = len(y),len(left_idxs),len(right_idxs)\n",
        "    e_l,e_r=self._entropy(y[left_idxs]),self._entropy(y[right_idxs])\n",
        "    child_entropy=(n_l/n)*e_l+(n_r/n)*e_r\n",
        "    information_gain= child_entropy\n",
        "    return information_gain\n",
        "  def _entropy(self,y):\n",
        "    fid3=np.mean(y)\n",
        "    if fid3==0 or fid3==1:\n",
        "      return 0\n",
        "    return -fid3*np.log(fid3)- (1-fid3)*np.log(1-fid3)\n",
        "  def predict(self,X):\n",
        "    y_pred=np.full(X.shape[0],self.intial_prediction)\n",
        "    for tree in self.trees:\n",
        "      y_pred+=self.learning_rate*tree.predict(X)\n",
        "    return y_pred\n",
        "  def _traverse_tree(self,x,node):\n",
        "    if node.is_leaf_node():\n",
        "      return node.value\n",
        "    if x[node.feature]<=node.threshold:\n",
        "      return self._traverse_tree(x,node.left)\n",
        "    return self._traverse_tree(x,node.right)\n",
        "\n",
        "class RandomForest:\n",
        "  def __init__(self,n_trees=10,n_features=None):\n",
        "    self.n_trees=n_trees\n",
        "    self.n_features=n_features\n",
        "    self.trees=[]\n",
        "  def _most_common_label(self,y):\n",
        "    unique_labels,counts=np.unique(y,return_counts=True)\n",
        "    return unique_labels[np.argmax(counts)]\n",
        "  def fit(self,X,y):\n",
        "    self.trees=[]\n",
        "    for _ in range(self.n_trees):\n",
        "      tree=DecisionTree()\n",
        "      X_sample,y_sample=self._bootstrap_sample(X,y)\n",
        "      tree.fit(X_sample,y_sample)\n",
        "      self.trees.append(tree)\n",
        "  def _bootstrap_sample(self,X,y):\n",
        "    n_samples,n_features=X.shape\n",
        "    idxs=np.random.choice(n_samples,n_samples,replace=True)\n",
        "    return X[idxs],y[idxs]\n",
        "  def predict(self,X):\n",
        "    preds=np.array([tree.predict(X) for tree in self.trees])\n",
        "    tree_preds=np.swapaxes(preds,0,1)\n",
        "    preds=np.array([self._most_common_label(tree_pred) for tree_pred in tree_preds])\n",
        "    return pred"
      ],
      "metadata": {
        "id": "7JCkzBpMOLhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re=GradientBoostingRegressor(n_estimators=100,learning_rate=0.1,max_depth=10)\n",
        "re.fit(X,y)\n",
        "y_pred=re.predict(X)\n",
        "mse=np.mean((y-y_pred)**2)\n",
        "print(f\"mean square error : {mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nNRFyyfRbKE",
        "outputId": "50fdb5e5-9f76-4c73-f103-606b16972815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean square error : 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iMp2b0poUqUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q00_Ux_BUYtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hr_9RdluUWpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score=r2_score_percentage(y,y_pred)\n",
        "print(r2_score)"
      ],
      "metadata": {
        "id": "QASgXzNaR8uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ADA boosting using sklern"
      ],
      "metadata": {
        "id": "jywvxEbaVIft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "5U1Erh0qVNSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([[1,2],[2,3],[3,4],[4,5],[5,6]])\n",
        "y=np.array([1,1,0,0,0])\n",
        "clf=AdaBoostClassifier(n_estimators=50,learning_rate=0.1,random_state=42,algorithm='SAMME')\n",
        "clf.fit(X,y)\n",
        "y_pred=clf.predict(X)\n"
      ],
      "metadata": {
        "id": "guWIT8trVXh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(y_test,y_pred):\n",
        "  return np.mean(y_test==y_pred)\n",
        "accuracy=acc(y,y_pred)"
      ],
      "metadata": {
        "id": "0Xy3sxSVVy2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuWx2TA-V-Ow",
        "outputId": "f49ff5f9-8cdd-46e2-d371-5b54308ef0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AqqVCDubV_CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#without inbuilt functions"
      ],
      "metadata": {
        "id": "ZcQ82hicWB6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoostWithTreeStump:\n",
        "  def __init__(self,n_estimators=50):\n",
        "    self.n_estimators=n_estimators\n",
        "    self.alphas=[]\n",
        "    self.models=[]\n",
        "  def fit(X,y):\n",
        "    m=X.shape[0]\n",
        "    weights=np.ones(m)/m\n",
        "    for _ in range(self.n_estimators):\n",
        "      stump=DecisionTree(max_depth=1)\n",
        "      stump.fit(X,y)\n",
        "      predictions=stump.predict(X)\n",
        "      error=np.sum(predictions !=y)/m\n",
        "      if error==0:\n",
        "        alpha=1e10\n",
        "      else:\n",
        "        alpha=0.5*np.log((1-error)/error)\n",
        "      self.alphas.append(alpha)\n",
        "      self.models.append(stump)\n",
        "      new_weights=[]\n",
        "      for i in range(m):\n",
        "        if predictions[i]==y[i]:\n",
        "          new_weight=weights[i]*np.exp(-alpha)\n",
        "        else:\n",
        "          new_weight=weights[i]*np.exp(-alpha)\n",
        "        new_weights.append(new_weight)\n",
        "      min_weight=1e-10\n",
        "      new_weights=[max(W,min_weight) for W in new_weights]\n",
        "      weight_sum=np.sum(new_weights)\n",
        "      weights=[W/weight_sum for W in new_weights]\n",
        "      #weights/=np.sum(weights)\n",
        "      cumulative_weights=np.cumsum(weights)\n",
        "      random_values=np.random.rand(m)\n",
        "      indices=np.searchsorted(cumulative_weights,random_values)\n",
        "      X,y=X[indices],y[indices]\n",
        "    def predict(self,X):\n",
        "      m=len(x)\n",
        "      final_pred=np.zeros(m)\n",
        "      for alpha, model in zip(self.alphas, self.models):\n",
        "        predictions=model.predict(X)\n",
        "        final_pred+=alpha*predictions\n",
        "      return np.where(final_pred>0,1,0)\n"
      ],
      "metadata": {
        "id": "EUJR7AvNWGxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}